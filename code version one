import streamlit as st
import random
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.optim as optim
from midiutil import MIDIFile
from pydub import AudioSegment
import io

st.title("Music-Evolving AI Web App")

# User inputs
genre = st.selectbox("Genre", ["pop", "jazz", "classical", "rock"])
key_root = st.selectbox("Key Root", ["C", "D", "E", "F", "G", "A", "B"])
mode = st.selectbox("Mode", ["major", "minor", "dorian"])
emotion = st.selectbox("Emotion", ["happy", "sad", "suspenseful"])
generations = st.slider("Generations", 10, 100, 20)

if st.button("Generate Music"):
    with st.spinner("Evolving music..."):
        # Define scales, notes, etc. based on inputs
        root = {"C": 60, "D": 62, "E": 64, "F": 65, "G": 67, "A": 69, "B": 71}[key_root]
        scales = {"major": [0, 2, 4, 5, 7, 9, 11], "minor": [0, 2, 3, 5, 7, 8, 10]}
        melody_notes = [root + i + 12 for i in scales[mode]]

        # Simplified evolve function
        def generate_individual():
            return {"melody": [(random.choice(melody_notes), 1, 100) for _ in range(32)]}
        def evolve(gens):
            pop = [generate_individual() for _ in range(20)]
            for gen in range(gens):
                pop.sort(key=lambda x: sum(n for n, _, _ in x["melody"]), reverse=True)
                pop = pop[:10] + [generate_individual() for _ in range(10)]
            return max(pop, key=lambda x: sum(n for n, _, _ in x["melody"]))
        best_ind = evolve(generations)

        # LSTM (simplified)
        class MusicLSTM(nn.Module):
            def __init__(self): ...
            def forward(self, x): ...
        # Placeholder training

        # Visualization
        fig, ax = plt.subplots()
        times = [0] + [1] * 31
        ax.plot(times, [n for n, _, _ in best_ind["melody"]])
        st.pyplot(fig)

        # Save MIDI and convert to WAV
        midi = MIDIFile(1)
        time = 0
        for note, dur, vol in best_ind["melody"]:
            midi.addNote(0, 0, note, time, dur, vol)
            time += dur
        midi_buffer = io.BytesIO()
        midi.writeFile(midi_buffer)
        midi_buffer.seek(0)
        wav_buffer = io.BytesIO()
        sound = AudioSegment.from_file(midi_buffer, format="mid")
        sound.export(wav_buffer, format="wav")
        wav_buffer.seek(0)

        # Output
        st.audio(wav_buffer, format="audio/wav")
        st.download_button("Download MIDI", midi_buffer, file_name="generated_music.mid")
        st.download_button("Download WAV", wav_buffer, file_name="generated_music.wav")